{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "# 시각화 결과가 선명하게 표시되도록\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "df = pd.read_csv(\"word2vec_wrangling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exercise_name</th>\n",
       "      <th>Content_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>PT</td>\n",
       "      <td>💯 What I try to educate my clients around, doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>검도</td>\n",
       "      <td>#20200115\\n저녁 초대!\\n와인잔 속에 비치는\\n모든 것들이 화려한\\n도심속...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>기구필라테스</td>\n",
       "      <td>#오늘의동작\\n캐딜락 동작의 완성 '행잉'\\n⠀\\n중력을 이용해 척추를 늘려주고\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>다빈치바디보드</td>\n",
       "      <td>#mbn생생정보마당 \\n#고투\\n#고투GX\\n#다빈치바디보드\\n#생방송 #GOTOL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>드럼스틱</td>\n",
       "      <td>#드럼스틱 #고무팁 #테크라스틱 #전자드럼용스틱\\n\\n1. 전자드럼타격시 덜 시끄럽...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  exercise_name                                        Content_txt\n",
       "0            PT  💯 What I try to educate my clients around, doe...\n",
       "1            검도  #20200115\\n저녁 초대!\\n와인잔 속에 비치는\\n모든 것들이 화려한\\n도심속...\n",
       "2        기구필라테스  #오늘의동작\\n캐딜락 동작의 완성 '행잉'\\n⠀\\n중력을 이용해 척추를 늘려주고\\n...\n",
       "3       다빈치바디보드  #mbn생생정보마당 \\n#고투\\n#고투GX\\n#다빈치바디보드\\n#생방송 #GOTOL...\n",
       "4          드럼스틱  #드럼스틱 #고무팁 #테크라스틱 #전자드럼용스틱\\n\\n1. 전자드럼타격시 덜 시끄럽..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soynlp\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    # 개행문자 제거\n",
    "    text = re.sub('\\\\\\\\n', ' ', text)\n",
    "    # 특수문자 제거\n",
    "    # 특수문자나 이모티콘 등은 때로는 의미를 갖기도 하지만 여기에서는 제거했습니다.\n",
    "    # text = re.sub('[?.,;:|\\)*~`’!^\\-_+<>@\\#$%&-=#}※]', '', text)\n",
    "    # 한글, 영문, 숫자만 남기고 모두 제거하도록 합니다.\n",
    "    # text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', ' ', text)\n",
    "    # 한글, 영문만 남기고 모두 제거하도록 합니다.\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z]', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(exercise_name):\n",
    "    file_name = \"#\" + exercise_name + \"_sum.txt\"\n",
    "    file_1 = \"/Users/noopy/FitCuration/\" + file_name\n",
    "    text = open(file_1, 'r', -1, \"UTF-8\", errors=\"ignore\").read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_content = open_file(\"자이로토닉\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   자이로토닉  gyrotonic 비교할 수 없는 레슨 퀄리티     월 프롬과 함께하세요   위례신도시 No      월 이벤트  신규 개인레슨   회   만원 선착순   분   신규 그룹레슨 최대    할인 개월수 별로 할인율 상이    인 이상 단체등록 시 신규클래스 오픈      인 소수 그룹레슨 미국 BBU 장비        개인레슨 미국 Gratz  BBU  Gyrotonic 장비     클래식필라테스  자이로토닉    프롬필라테스 위례동로     우성메디피아  층                  안녕하세요  에코필라테스 플러스입니다     설 연휴 전까지 열심히 운동하러 오시는 우리 멋찐 회원님들을 맞이하려 저는 출근하자마자 부랴부랴 청소를 끝마쳤답니다      어서 센터를 뜨겁게 달구어 주세요     오늘도 평화로운 에코필라테스 플러스와 함께        자세한 문의 및 상담                 카카오 오픈채팅   에코필라테스플러스   blog naver com ecopilatesplus   첨먹어보는 춰컬릿    사만다 에듀케이터  samantha jrobinsonhk 의 달달한간식   맛있다   ㅎㅎ자꾸먹게되는군요      아치앤컬  필라테스  폴스타필라테스  자이로토닉  자이로토닉   자이로키네시스  자이로키네시스   청담필라테스  청담자이로토닉  부산필라테스  부산자이로토닉  archncurl  pilates  polestarpilates  gyrotonic  gyrokinesis 효지원장님  misa limepilates 의 선물    교육듣느라 안그래도 정신없을텐데 요렇게 또 챙겨주니 넘 고마워요 이쁘게 잘쓸게용         아치앤컬  필라테스  폴스타필라테스  자이로토닉  자이로토닉강사  자이로키네시스  자이로키네시스   청담필라테스  부산필라테스  청담자이로토닉  부산자이로토닉  archncurl  pilates  polestarpilates  gyrotonic  gyrokinesis  지유필라테스 자이로토닉 G YOU '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_content = preprocessing(sample_content)\n",
    "sample_content[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec 모델 학습에 로그를 찍을 수 있도록 합니다.\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 948 ms, sys: 13.1 ms, total: 961 ms\n",
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "# %time을 찍어주면 해당 코드를 실행할 때 걸리는 시간을 출력해 줍니다\n",
    "%time sentences = df['Content_txt'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noopy/opt/anaconda3/lib/python3.7/site-packages/soynlp/tokenizer/_tokenizer.py:19: FutureWarning: Possible nested set at position 13\n",
      "  ('english & latin', re.compile(u\"[a-zA-ZÀ-ÿ]+[[`']?s]*|[a-zA-ZÀ-ÿ]+\", re.UNICODE))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<soynlp.tokenizer._tokenizer.RegexTokenizer at 0x7fecc0b55210>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import RegexTokenizer\n",
    "\n",
    "tokenizer = RegexTokenizer()\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['자이로토닉', 'gyrotonic', '비교할', '수', '없는', '레슨', '퀄리티', '월', '프롬과', '함께하세요']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전처리 이후의 샘플 텍스트로 토큰화\n",
    "tokened_content = tokenizer.tokenize(sample_content)\n",
    "tokened_content[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43663\n"
     ]
    }
   ],
   "source": [
    "print(len(tokened_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 00:32:23,593 : INFO : collecting all words and their counts\n",
      "2020-02-03 00:32:23,594 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.6 s, sys: 23.9 ms, total: 16.6 s\n",
      "Wall time: 16.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 00:32:24,153 : INFO : collected 324341 word types from a corpus of 2300597 raw words and 61 sentences\n",
      "2020-02-03 00:32:24,154 : INFO : Loading a fresh vocabulary\n",
      "2020-02-03 00:32:25,685 : INFO : effective_min_count=1 retains 324341 unique words (100% of original 324341, drops 0)\n",
      "2020-02-03 00:32:25,686 : INFO : effective_min_count=1 leaves 2300597 word corpus (100% of original 2300597, drops 0)\n",
      "2020-02-03 00:32:26,489 : INFO : deleting the raw counts dictionary of 324341 items\n",
      "2020-02-03 00:32:26,494 : INFO : sample=0.001 downsamples 9 most-common words\n",
      "2020-02-03 00:32:26,495 : INFO : downsampling leaves estimated 2287695 word corpus (99.4% of prior 2300597)\n",
      "2020-02-03 00:32:27,172 : INFO : estimated required memory for 324341 words and 100 dimensions: 421643300 bytes\n",
      "2020-02-03 00:32:27,173 : INFO : resetting layer weights\n",
      "2020-02-03 00:33:14,694 : INFO : training model with 3 workers on 324341 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-02-03 00:33:15,221 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 00:33:15,235 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 00:33:15,241 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 00:33:15,241 : INFO : EPOCH - 1 : training on 2300597 raw words (569252 effective words) took 0.5s, 1043847 effective words/s\n",
      "2020-02-03 00:33:15,771 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 00:33:15,787 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 00:33:15,794 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 00:33:15,794 : INFO : EPOCH - 2 : training on 2300597 raw words (569235 effective words) took 0.5s, 1036958 effective words/s\n",
      "2020-02-03 00:33:16,355 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 00:33:16,368 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 00:33:16,374 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 00:33:16,375 : INFO : EPOCH - 3 : training on 2300597 raw words (569251 effective words) took 0.6s, 988706 effective words/s\n",
      "2020-02-03 00:33:16,936 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 00:33:16,945 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 00:33:16,951 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 00:33:16,952 : INFO : EPOCH - 4 : training on 2300597 raw words (569251 effective words) took 0.6s, 994865 effective words/s\n",
      "2020-02-03 00:33:17,514 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-03 00:33:17,529 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-03 00:33:17,535 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-03 00:33:17,536 : INFO : EPOCH - 5 : training on 2300597 raw words (569239 effective words) took 0.6s, 982860 effective words/s\n",
      "2020-02-03 00:33:17,537 : INFO : training on a 11502985 raw words (2846228 effective words) took 2.8s, 1001453 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7fb3fe01b750>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초기화 및 모델 학습\n",
    "from gensim.models import word2vec\n",
    "\n",
    "%time tokens = sentences.apply(tokenizer.tokenize)\n",
    "\n",
    "# 모델 학습\n",
    "model = word2vec.Word2Vec(tokens, min_count=1)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_Twitter = [\"입니다\",\"있는\",\"있습니다\",\"같은\",\"안녕하세요\",\"고마워요\",\"있어요\",\"있게\"\\\n",
    "                     ,\"있도록\",\"부탁드립니다\",\"하는\",\"합니다\",\"할\",\"하세요\",\"하기\",\"해\",\"됩니다\",\"하여\",'잘','된','되고','되어','되었습니다',\"없는\",\"드립니다\"\\\n",
    "                    ,\"되기\",\"하시는\",\"하고\",\"않을\",\"같다\",\"싶다\",\"이런\",\"저런\",\"그런\",'바랍니다'\\\n",
    "                    ,\"했습니다\",\"했다\",\"해드립니다\",\"하신\",\"하실\",\"않고\",\"해요\",\"가능합니다\",\"하고싶으신\"\\\n",
    "                    ,\"않으며\",\"주세요\",\"오세요\"]\n",
    "\n",
    "stopwords_mecab = ['수','퀄리티','도시','분','전문','스타','년','원',\\\n",
    "                   '월','화','수','목','금','시','앤','일','그램','문'] \n",
    "\n",
    "stopwords = stopwords_mecab + stopwords_Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-03 00:33:25,025 : INFO : saving Word2Vec object under my_second_model, separately None\n",
      "2020-02-03 00:33:25,026 : INFO : storing np array 'vectors' to my_second_model.wv.vectors.npy\n",
      "2020-02-03 00:33:25,323 : INFO : not storing attribute vectors_norm\n",
      "2020-02-03 00:33:25,324 : INFO : storing np array 'syn1neg' to my_second_model.trainables.syn1neg.npy\n",
      "2020-02-03 00:33:25,607 : INFO : not storing attribute cum_table\n",
      "2020-02-03 00:33:26,140 : INFO : saved my_second_model\n"
     ]
    }
   ],
   "source": [
    "# 모델 이름을 지정하고 저장한다.\n",
    "model_name = 'my_second_model'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 모델은 여기서 꺼내면 된다\n",
    "import pandas\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec.load(\"my_second_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324341"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 사전 수\n",
    "len(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['운동',\n",
       " '다이어트',\n",
       " '요가',\n",
       " '필라테스',\n",
       " '월',\n",
       " '시',\n",
       " '일',\n",
       " '운동하는여자',\n",
       " '수',\n",
       " '일상',\n",
       " 'a',\n",
       " '더',\n",
       " 't',\n",
       " '분',\n",
       " '함께']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 사전에서 상위 10개만 보기\n",
    "vocab = model.wv.vocab\n",
    "sorted(vocab, key=vocab.get, reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'운동': <gensim.models.keyedvectors.Vocab at 0x7f7ef474be50>,\n",
       " '다이어트': <gensim.models.keyedvectors.Vocab at 0x7f7ef474bf10>,\n",
       " '요가': <gensim.models.keyedvectors.Vocab at 0x7f7ef48cf710>,\n",
       " '필라테스': <gensim.models.keyedvectors.Vocab at 0x7f7e71733e10>,\n",
       " '월': <gensim.models.keyedvectors.Vocab at 0x7f7ef48fc550>,\n",
       " '시': <gensim.models.keyedvectors.Vocab at 0x7f7ef49d8b10>,\n",
       " '일': <gensim.models.keyedvectors.Vocab at 0x7f7ef49eb210>,\n",
       " '운동하는여자': <gensim.models.keyedvectors.Vocab at 0x7f7ef474bed0>,\n",
       " '수': <gensim.models.keyedvectors.Vocab at 0x7f7e71782150>,\n",
       " '일상': <gensim.models.keyedvectors.Vocab at 0x7f7e71733f10>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counter로 자주 등장하는 단어 보기\n",
    "from collections import Counter\n",
    "dict(Counter(vocab).most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'encourage'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가장 적게 등장하는 단어\n",
    "min(vocab, key=vocab.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('씨티포레스티벌', 0.9979838728904724),\n",
       " ('기능성', 0.9974091649055481),\n",
       " ('판교', 0.9973074197769165),\n",
       " ('W', 0.9963376522064209),\n",
       " ('가희와', 0.9961326718330383),\n",
       " ('근막', 0.995990514755249),\n",
       " ('김포요가', 0.9957764148712158),\n",
       " ('점핑핏', 0.9956825971603394),\n",
       " ('외에도', 0.9956777095794678),\n",
       " ('힙합발레', 0.995653510093689)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('힙레')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('근육', 0.9995039701461792),\n",
       " ('가즈아', 0.9991205930709839),\n",
       " ('유아체육', 0.9989883899688721),\n",
       " ('폴댄스', 0.9987660646438599),\n",
       " ('광주', 0.9987014532089233),\n",
       " ('복근운동', 0.9985569715499878),\n",
       " ('태권도', 0.9985353350639343),\n",
       " ('모델', 0.9984759092330933),\n",
       " ('스파링', 0.9983445405960083),\n",
       " ('MMA', 0.9982408881187439)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('복근')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('엄청', 0.998993992805481),\n",
       " ('등등', 0.9989675283432007),\n",
       " ('다리', 0.9986965656280518),\n",
       " ('하네요', 0.9986326694488525),\n",
       " ('힘들게', 0.9986114501953125),\n",
       " ('걱정', 0.9986083507537842),\n",
       " ('다행히', 0.9985339641571045),\n",
       " ('고마워', 0.9985274076461792),\n",
       " ('힘들고', 0.9983700513839722),\n",
       " ('평생', 0.9983628988265991)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('척추')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('타바타운동', 0.9963933229446411),\n",
       " ('퍼스널트레이너', 0.9963120222091675),\n",
       " ('근력운동', 0.9958586692810059),\n",
       " ('웨이트', 0.9956011772155762),\n",
       " ('안다르', 0.9955255389213562),\n",
       " ('홈트', 0.995509922504425),\n",
       " ('바른자세', 0.9954653382301331),\n",
       " ('자기관리', 0.9952776432037354),\n",
       " ('근육기능운동', 0.9952510595321655),\n",
       " ('체력증진', 0.9951571822166443)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['척추','건강'], negative=['우한'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('운동영상', 0.9981263875961304),\n",
       " ('대한폴댄스연맹', 0.9980324506759644),\n",
       " ('팍팍', 0.9976912140846252),\n",
       " ('축구', 0.9974087476730347),\n",
       " ('아침운동', 0.9973322153091431),\n",
       " ('체력', 0.9972175359725952),\n",
       " ('운동시작', 0.9970873594284058),\n",
       " ('pointgym', 0.9970570802688599),\n",
       " ('점핑', 0.9969454407691956),\n",
       " ('작심삼일', 0.9968618750572205)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['척추','건강'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9884146"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('척추', '검도')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PT',\n",
       " '검도',\n",
       " '기구필라테스',\n",
       " '다빈치바디보드',\n",
       " '드럼스틱',\n",
       " '등산',\n",
       " '라틴댄스',\n",
       " '매트필라테스',\n",
       " '뮤직복싱',\n",
       " '바차타']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise_to_loop = df[\"exercise_name\"].to_list()\n",
    "\n",
    "\n",
    "exercise_to_loop.sort()\n",
    "exercise_to_loop[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_val = []\n",
    "\n",
    "def tuple(exercise_name,word):\n",
    "    return (word, model.wv.similarity(exercise_name,word))\n",
    "\n",
    "def show_similarity_for_each_exercise(word):\n",
    "    for item in exercise_to_loop:\n",
    "        vector_val.append(tuple(word, item))\n",
    "    return vector_val\n",
    "\n",
    "vector_list = show_similarity_for_each_exercise('복근')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('폴댄스', 0.9987661),\n",
       " ('플라잉필라테스', 0.9956836),\n",
       " ('크로스핏', 0.99524415),\n",
       " ('발레', 0.99482024),\n",
       " ('사이클', 0.9946428),\n",
       " ('요가쿠아', 0.9944515),\n",
       " ('조깅', 0.9943916),\n",
       " ('복싱', 0.99346507),\n",
       " ('수영', 0.99276334),\n",
       " ('패들보드', 0.9924408)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Sort(tup): \n",
    "    return(sorted(tup, key = lambda x: float(x[1]), reverse = True)) \n",
    "\n",
    "Sort(vector_list)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
